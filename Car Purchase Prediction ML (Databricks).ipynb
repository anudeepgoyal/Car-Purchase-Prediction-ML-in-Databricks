{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96816ed7-b08a-4ca3-abb9-f99880c3535d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Overview\n",
    "\n",
    "This notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n",
    "\n",
    "This notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5a57fff-c4da-4040-b180-c30670eef9eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6482be4c-f067-47c9-b0ac-35c938b94601",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Purchased' column exists.\nIndex(['User ID', 'Gender', 'Age', 'EstimatedSalary', 'Purchased'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# File location and type\n",
    "file_location = \"/FileStore/tables/suv_data.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options: set header to 'true' since your file contains headers\n",
    "suv_car_df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", \"false\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .load(file_location)\n",
    "\n",
    "# Convert the DataFrame to Pandas for easier processing with scikit-learn\n",
    "suv_car_pd = suv_car_df.toPandas()\n",
    "\n",
    "# Strip any leading/trailing spaces from the column names\n",
    "suv_car_pd.columns = suv_car_pd.columns.str.strip()\n",
    "\n",
    "# Check if 'Purchased' exists in the dataset\n",
    "if 'Purchased' in suv_car_pd.columns:\n",
    "    print(\"'Purchased' column exists.\")\n",
    "else:\n",
    "    print(\"'Purchased' column not found.\")\n",
    "\n",
    "# Display the column names to verify\n",
    "print(suv_car_pd.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd82bb99-1479-4d5c-be10-8c36df0f1d44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a view or table\n",
    "\n",
    "suv_car_pd.columns = suv_car_pd.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5f66379-6f7f-42ec-8e82-d0e0926a1721",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Purchased' column exists.\nIndex(['User ID', 'Gender', 'Age', 'EstimatedSalary', 'Purchased'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check if 'Purchased' exists in the dataset\n",
    "if 'Purchased' in suv_car_pd.columns:\n",
    "    print(\"'Purchased' column exists.\")\n",
    "else:\n",
    "    print(\"'Purchased' column not found.\")\n",
    "\n",
    "# Display the column names to verify\n",
    "print(suv_car_pd.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db9631f6-bb4a-42ca-8a3c-0d48af932331",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<command-2373370550541103>:12: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n  suv_car_pd.fillna(suv_car_pd.median(), inplace=True)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>382</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User ID</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>EstimatedSalary</th>\n      <th>Purchased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>97</td>\n      <td>1</td>\n      <td>1</td>\n      <td>43</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>392</td>\n      <td>1</td>\n      <td>17</td>\n      <td>44</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>155</td>\n      <td>0</td>\n      <td>8</td>\n      <td>65</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>64</td>\n      <td>0</td>\n      <td>9</td>\n      <td>78</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>382</td>\n      <td>1</td>\n      <td>1</td>\n      <td>96</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset and inspect its structure\n",
    "suv_car_pd = suv_car_df.toPandas()\n",
    "\n",
    "# Check the column names in the dataset\n",
    "suv_car_pd.columns\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "suv_car_pd.isnull().sum()\n",
    "\n",
    "# Assuming 'Price' is the target variable and other columns are features\n",
    "# Fill missing values with the median for numeric features\n",
    "suv_car_pd.fillna(suv_car_pd.median(), inplace=True)\n",
    "\n",
    "# Check the categorical columns in the dataset and encode them\n",
    "categorical_columns = suv_car_pd.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Convert categorical features to numeric using Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to all categorical columns\n",
    "for col in categorical_columns:\n",
    "    suv_car_pd[col] = label_encoder.fit_transform(suv_car_pd[col])\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = suv_car_pd.drop(columns=['Purchased'])  # Assuming 'Price' is the target variable\n",
    "y = suv_car_pd['Purchased']\n",
    "\n",
    "# Display the modified dataset\n",
    "suv_car_pd.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0253783a-cf25-44b2-b5c1-e52319cd5857",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 320\nTest set size: 80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf2e4440-2255-4a1d-b193-1fe9246a1592",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[10]: RandomForestRegressor(random_state=42)"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45c3f9bf-af7b-4c90-ba07-948a7aab7198",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.07148\nR-squared: 0.6858021978021979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa991290-fd9b-412d-9e3c-0f48bc7c364e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.09072143551886436\nR-squared: 0.6012244592577392\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model instantiation\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78c54a34-a42b-41a7-bc38-174a8e995e21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "354b4eb9-8bfc-490b-b1b9-7af8f088ed04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=GradientBoostingRegressor(), param_grid=param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcb90284-dc1d-4626-ac2d-5b3c763e906d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.08353264027673692\nR-squared: 0.6328235592231345\n"
     ]
    }
   ],
   "source": [
    "# Using the best parameters found by GridSearchCV\n",
    "best_model = GradientBoostingRegressor(\n",
    "    n_estimators=50, \n",
    "    learning_rate=0.1, \n",
    "    max_depth=3, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "mse_best = mean_squared_error(y_test, y_pred_best)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_best}\")\n",
    "print(f\"R-squared: {r2_best}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d2e098d-315b-43fa-adb8-6ddfd4fb4a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nRequirement already satisfied: xgboost in /local_disk0/.ephemeral_nfs/envs/pythonEnv-fa2973a6-fd07-40b8-ba91-f7791e6f2b44/lib/python3.9/site-packages (2.1.4)\nRequirement already satisfied: nvidia-nccl-cu12 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-fa2973a6-fd07-40b8-ba91-f7791e6f2b44/lib/python3.9/site-packages (from xgboost) (2.25.1)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.9/site-packages (from xgboost) (1.7.3)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.9/site-packages (from xgboost) (1.21.5)\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55e3fc73-4492-4652-a3c9-fdceb889382a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Purchased' column exists.\nIndex(['User ID', 'Gender', 'Age', 'EstimatedSalary', 'Purchased'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# File location and type\n",
    "file_location = \"/FileStore/tables/suv_data.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options: set header to 'true' since your file contains headers\n",
    "suv_car_df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", \"false\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .load(file_location)\n",
    "\n",
    "# Convert the DataFrame to Pandas for easier processing with scikit-learn\n",
    "suv_car_pd = suv_car_df.toPandas()\n",
    "\n",
    "# Strip any leading/trailing spaces from the column names\n",
    "suv_car_pd.columns = suv_car_pd.columns.str.strip()\n",
    "\n",
    "# Check if 'Purchased' exists in the dataset\n",
    "if 'Purchased' in suv_car_pd.columns:\n",
    "    print(\"'Purchased' column exists.\")\n",
    "else:\n",
    "    print(\"'Purchased' column not found.\")\n",
    "\n",
    "# Display the column names to verify\n",
    "print(suv_car_pd.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a88c38b-a3a1-49c3-84c2-046b530bc6ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<command-3592271566191607>:12: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n  suv_car_pd.fillna(suv_car_pd.median(), inplace=True)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>382</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User ID</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>EstimatedSalary</th>\n      <th>Purchased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>97</td>\n      <td>1</td>\n      <td>1</td>\n      <td>43</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>392</td>\n      <td>1</td>\n      <td>17</td>\n      <td>44</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>155</td>\n      <td>0</td>\n      <td>8</td>\n      <td>65</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>64</td>\n      <td>0</td>\n      <td>9</td>\n      <td>78</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>382</td>\n      <td>1</td>\n      <td>1</td>\n      <td>96</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset and inspect its structure\n",
    "suv_car_pd = suv_car_df.toPandas()\n",
    "\n",
    "# Check the column names in the dataset\n",
    "suv_car_pd.columns\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "suv_car_pd.isnull().sum()\n",
    "\n",
    "# Assuming 'Price' is the target variable and other columns are features\n",
    "# Fill missing values with the median for numeric features\n",
    "suv_car_pd.fillna(suv_car_pd.median(), inplace=True)\n",
    "\n",
    "# Check the categorical columns in the dataset and encode them\n",
    "categorical_columns = suv_car_pd.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Convert categorical features to numeric using Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to all categorical columns\n",
    "for col in categorical_columns:\n",
    "    suv_car_pd[col] = label_encoder.fit_transform(suv_car_pd[col])\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = suv_car_pd.drop(columns=['Purchased'])  # Assuming 'Price' is the target variable\n",
    "y = suv_car_pd['Purchased']\n",
    "\n",
    "# Display the modified dataset\n",
    "suv_car_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f180cfc-f28c-41fc-bd2e-b06c0d6aed68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MSE: 0.08147501836871768\nXGBoost R²: 0.6418680511265158\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the XGBoost model\n",
    "model_xgb = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost MSE: {mse_xgb}\")\n",
    "print(f\"XGBoost R²: {r2_xgb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8831328c-108f-43cf-9e82-b7cffaec5680",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting lightgbm\n  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.9/site-packages (from lightgbm) (1.7.3)\nRequirement already satisfied: numpy>=1.17.0 in /databricks/python3/lib/python3.9/site-packages (from lightgbm) (1.21.5)\nInstalling collected packages: lightgbm\nSuccessfully installed lightgbm-4.6.0\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bcc29a4-8241-4ed2-a633-f6a1070f00d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Purchased' column exists.\nIndex(['User ID', 'Gender', 'Age', 'EstimatedSalary', 'Purchased'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# File location and type\n",
    "file_location = \"/FileStore/tables/suv_data.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options: set header to 'true' since your file contains headers\n",
    "suv_car_df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", \"false\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .load(file_location)\n",
    "\n",
    "# Convert the DataFrame to Pandas for easier processing with scikit-learn\n",
    "suv_car_pd = suv_car_df.toPandas()\n",
    "\n",
    "# Strip any leading/trailing spaces from the column names\n",
    "suv_car_pd.columns = suv_car_pd.columns.str.strip()\n",
    "\n",
    "# Check if 'Purchased' exists in the dataset\n",
    "if 'Purchased' in suv_car_pd.columns:\n",
    "    print(\"'Purchased' column exists.\")\n",
    "else:\n",
    "    print(\"'Purchased' column not found.\")\n",
    "\n",
    "# Display the column names to verify\n",
    "print(suv_car_pd.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a72ad341-9920-4126-801d-8cbcc6bf0c75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<command-3592271566191611>:12: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n  suv_car_pd.fillna(suv_car_pd.median(), inplace=True)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>382</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User ID</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>EstimatedSalary</th>\n      <th>Purchased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>97</td>\n      <td>1</td>\n      <td>1</td>\n      <td>43</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>392</td>\n      <td>1</td>\n      <td>17</td>\n      <td>44</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>155</td>\n      <td>0</td>\n      <td>8</td>\n      <td>65</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>64</td>\n      <td>0</td>\n      <td>9</td>\n      <td>78</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>382</td>\n      <td>1</td>\n      <td>1</td>\n      <td>96</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset and inspect its structure\n",
    "suv_car_pd = suv_car_df.toPandas()\n",
    "\n",
    "# Check the column names in the dataset\n",
    "suv_car_pd.columns\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "suv_car_pd.isnull().sum()\n",
    "\n",
    "# Assuming 'Price' is the target variable and other columns are features\n",
    "# Fill missing values with the median for numeric features\n",
    "suv_car_pd.fillna(suv_car_pd.median(), inplace=True)\n",
    "\n",
    "# Check the categorical columns in the dataset and encode them\n",
    "categorical_columns = suv_car_pd.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Convert categorical features to numeric using Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to all categorical columns\n",
    "for col in categorical_columns:\n",
    "    suv_car_pd[col] = label_encoder.fit_transform(suv_car_pd[col])\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = suv_car_pd.drop(columns=['Purchased'])  # Assuming 'Price' is the target variable\n",
    "y = suv_car_pd['Purchased']\n",
    "\n",
    "# Display the modified dataset\n",
    "suv_car_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a54b3cd2-4fab-402f-93a5-2e0c34326cec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beca84a8-6c3f-47f9-8a0b-c2e65b7ae6fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000027 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 221\n[LightGBM] [Info] Number of data points in the train set: 320, number of used features: 4\n[LightGBM] [Info] Start training from score 0.359375\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nLightGBM MSE: 0.0657040642677618\nLightGBM R²: 0.7111909262955525\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize and fit the LightGBM model\n",
    "model_lgb = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model_lgb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lgb = model_lgb.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "mse_lgb = mean_squared_error(y_test, y_pred_lgb)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "\n",
    "print(f\"LightGBM MSE: {mse_lgb}\")\n",
    "print(f\"LightGBM R²: {r2_lgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cb845e8-25ed-4d22-925c-8e93aeaef67a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MSE: 0.0900799269570916\nSVR R²: 0.6040442771116853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Initialize and fit the SVR model\n",
    "model_svr = SVR(kernel='rbf', C=100, epsilon=0.1)\n",
    "model_svr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svr = model_svr.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "\n",
    "print(f\"SVR MSE: {mse_svr}\")\n",
    "print(f\"SVR R²: {r2_svr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ccf259a-da3d-41ae-926a-8c83f41a3b5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated MSE: 0.0924363212792697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "best_model = GradientBoostingRegressor(\n",
    "    n_estimators=50, \n",
    "    learning_rate=0.1, \n",
    "    max_depth=3, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Use cross-validation on the GradientBoostingRegressor\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "print(f\"Cross-validated MSE: {-cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5271d44d-4bcd-4b3b-8e8a-cf41197ef331",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 221\n[LightGBM] [Info] Number of data points in the train set: 320, number of used features: 4\n[LightGBM] [Info] Start training from score 0.359375\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nLightGBM MSE: 0.0657040642677618\nLightGBM R²: 0.7111909262955525\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Initialize and fit the LightGBM model\n",
    "model_lgb = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model_lgb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lgb = model_lgb.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "mse_lgb = mean_squared_error(y_test, y_pred_lgb)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "\n",
    "print(f\"LightGBM MSE: {mse_lgb}\")\n",
    "print(f\"LightGBM R²: {r2_lgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1226c9bc-e601-4eaf-bb77-11b2fa612952",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression MSE: 0.0875\nLogistic Regression R²: 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize and fit the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "mse_log_reg = mean_squared_error(y_test, y_pred_log_reg)\n",
    "r2_log_reg = r2_score(y_test, y_pred_log_reg)\n",
    "\n",
    "print(f\"Logistic Regression MSE: {mse_log_reg}\")\n",
    "print(f\"Logistic Regression R²: {r2_log_reg}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "2025-02-27 - DBFS Example",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
